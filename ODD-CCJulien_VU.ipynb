{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"ODD-CCJulien_VU.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"2uEtDettrjWO"},"source":["# Outils d'optimisation pour les sciences des données et de la décision - Contrôle continu\n","\n","#Julien VU\n","\n","# Master 2 ID 2020-2021\n","\n","## Date de rendu : 22 janvier 2021\n","\n","## Modalités de rendu\n","\n","- Ce notebook est à rendre **individuellement**. Votre rendu devra comporter vos nom et prénom(s). Les réponses aux différentes questions devront être incorporées au notebook, et la partie pratique devra pouvoir être exécutée par l'enseignant.\n","\n","- Votre version du notebook est à envoyer par mail à l'adresse clement.royer@dauphine.psl.eu. La date limite est fixée au **22 janvier 2021**."]},{"cell_type":"markdown","metadata":{"id":"H5MIluAArjWe"},"source":["## Ressources utiles\n","\n","- *La version la plus récente de ce notebook se trouve dans l'onglet* Fichiers *de l'équipe Teams associée au cours, ou sur [ce lien](https://www.lamsade.dauphine.fr/~croyer/ensdocs/ODD/ODD-CC.ipynb).*\n","\n","- *Le polycopié de cours est disponible [ici](https://www.lamsade.dauphine.fr/~croyer/ensdocs/ODD/PolyODD.pdf).*\n","\n","- *Ce notebook utilise LaTeX pour la partie mathématiques.* ***Le bloc ci-dessous devra être executé pour permettre d'éditer le notebook de la même manière qu'un document LaTeX (en permettant, notamment, aux équations d'être numérotées et référencées dans le même bloc).***"]},{"cell_type":"code","metadata":{"id":"tI1Ppz77rjWg","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1609969897923,"user_tz":-60,"elapsed":659,"user":{"displayName":"JULIEN VU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-WovJPI2yPidc_awdc77pL4cna4IDF3nnYW07Iw=s64","userId":"06342654057600854555"}},"outputId":"70aa963b-c1ab-4088-9000-334936039754"},"source":["%%javascript\n","MathJax.Hub.Config({\n","    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n","});"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["MathJax.Hub.Config({\n","    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n","});"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"6NAtkF6drjWj"},"source":["- Des macros LaTeX sont définies ci-dessous (mais n'apparaissent plus une fois le bloc exécuté). N'hésitez pas à incorporer vos propres macros !\n","\n","$$\n","\\newcommand{\\E}[1]{\\operatorname{\\mathbb{E}}\\left[#1\\right]}\n","\\DeclareMathOperator*{\\argmin}{\\text{argmin}}\n","\\def\\R{{\\mathbb{R}}}\n","\\def\\vz{{\\mathbf{z}}}\n","\\def\\vy{{\\mathbf{y}}}\n","\\def\\vx{{\\mathbf{x}}}\n","\\def\\vw{{\\mathbf{w}}}\n","\\def\\vv{{\\mathbf{v}}}\n","\\def\\vu{{\\mathbf{u}}}\n","\\def\\vq{{\\mathbf{q}}}\n","\\def\\ve{{\\mathbf{e}}}\n","\\def\\va{{\\mathbf{a}}}\n","\\def\\mX{{\\mathbf{X}}}\n","\\def\\mQ{{\\mathbf{Q}}}\n","\\def\\calC{{\\mathcal{C}}}\n","\\def\\setB{{\\mathcal{B}}}\n","\\newcommand{\\T}{\\mathrm{T}}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"E9I_Sg_yrjWj"},"source":["### Notations\n","\n","- Dans la suite, $d$ et $n$ désigneront toujours des entiers supérieurs ou égaux à 1.\n","- Pour tout vecteur $\\vw \\in \\R^d$, le $i$-ème coefficient de $\\vw$ sera noté $[\\vw]_i$."]},{"cell_type":"markdown","metadata":{"id":"_2mV_wOgrjWk"},"source":["# Sujet du notebook : Algorithmes de descente par coordonnées\n","\n","Les méthodes de descente par coordonnées (ou *coordinate descent* en anglais) sont une classe d'algorithmes qui a connu un regain d'intérêt avec l'arrivée des problèmes de traitement de données massives, pour lesquels il peut être trop coûteux d'agir sur toutes les variables simultanément. Si ces approches sont parmi les plus anciennes, elles ont été revisitées au cours des deux dernières décennies et sont toujours un sujet de recherche actif.\n","\n","Le but de ce notebook est donc de servir d'introduction aux méthodes de descente par coordonnées, dans un contexte générique mais aussi adapté à l'optimisation *parcimonieuse* ou creuse, pour laquelle on cherche des solutions possédant le plus de coefficients nuls possible."]},{"cell_type":"markdown","metadata":{"id":"1fMzZdv0rjWk"},"source":["# Partie I - Bases des méthodes de descente par coordonnées"]},{"cell_type":"markdown","metadata":{"id":"vIhTflH6rjWk"},"source":["Pour introduire le principe des méthodes de descente par coordonnées, on considère un problème générique de la forme \n","$$\n","    \\min_{\\vw \\in \\R^d} f(\\vw),\n","$$\n","où la fonction $f$ est supposée convexe et de classe $\\calC^1$.\n"," \n","Un algorithme de descente par coordonnées part d'un point $\\vw_0 \\in \\R^d$; à chaque itération $k$, la méthode choisit un indice $i_k \\in \\{1,\\dots,d\\}$, une taille de pas $\\alpha_k>0$, et effectue l'itération suivante :\n","\\begin{equation}\n","\\label{eq:dcit} \n","    \\vw_{k+1} := \\vw_k - \\alpha_k \\nabla_{i_k} f(\\vw_k) \\ve_{i_k},\n","\\end{equation}\n","où $\\nabla_{i_k}$ est une notation qui désigne la dérivée partielle par rapport à la $i_k$-ème coordonnée, càd \n","$\\nabla_{i_k} f(\\vw) = [\\nabla f(\\vw)]_{i_k}$ pour tout $\\vw \\in \\R^d$, et $\\ve_{i_k}$ désigne le $i_k$-ème vecteur de la base canonique de $\\R^d$.\n","\n","Le but intrinsèque d'une telle méthode est donc de ramener la résolution d'un problème en $d$ dimensions à celle d'une suite de problèmes en une dimension, en modifiant une coordonnée à la fois. Dans le cas général, il ne suffira pas de faire $d$ itérations pour obtenir la convergence, en revanche des propriétés telles que la séparabilité permettent de garantir la pertinence d'un tel procédé.\n","\n","## I - A) Propriétés élémentaires\n","\n","**Question 1** On peut réécrire l'itération \\eqref{eq:dcit} comme $\\vw_{k+1}:=\\vw_k+c_k \\ve_{i_k}$, où\n","\\begin{equation}\n","\\label{eq:dcitpb}\n","    c_k = \\argmin_{c \\in \\R}\\ q_k(c), \\quad \\mbox{avec} \\quad q_k(c):=\\nabla_{i_k} f(\\vw_k) (c-[\\vw_k]_{i_k}) \n","    + \\frac{1}{2\\alpha_k}(c-[\\vw_k]_{i_k})^2.\n","\\end{equation}\n","\n","**1-a)** Justifier que ce problème est fortement convexe, et donner la valeur explicite de $c_k$. \n","\n","**1-b)** À quel principe algorithmique vu en cours pouvez-vous relier la caractérisation \\eqref{eq:dcitpb} ?\n","\n","**Question 2** Une des hypothèses classiques d'analyse de ce genre de méthodes consiste à supposer que le gradient de $f$ est lipschitzien selon chaque coordonnée, c'est-à-dire qu'il existe $d$ réels positifs $L_1,\\dots,L_d$ tels que\n","$$\n","    \\forall i=1,\\dots,d,\\ \\forall (\\vw,\\vv) \\in (\\R^d)^2, \n","    \\quad \\left| \\nabla_i f(\\vw) - \\nabla_i f(\\vv) \\right| \n","    \\le L_i \\|\\vw-\\vv\\|.\n","$$\n","On peut alors définir la *constante de Lipschitz par coordonnées* $L_{\\max}:= \\max_{1 \\le i \\le d} L_i$.\n","Justifier que si le gradient $\\nabla f$ est $L$-lipschitzien, alors $L_{\\max} >= \\frac{L}{d}$.\n","\n","**Question 3** Par analogie avec les approches de type descente de gradient, pourquoi peut-on envisager le choix de taille de pas $\\alpha_k = \\frac{1}{L_{i_k}}$ à l'itération $k$ de l'algorithme ? Quel serait l'intérêt de choisir ce pas plutôt que $\\frac{1}{L}$, comme vu en cours, ou que $\\frac{1}{L_{\\max}}$ ?\n"," \n","\n","## *Réponses de la partie I - A)*\n","\n","*Votre réponse à la question 1*\n","\n","*1-a)* On sait que la fonction $f$ est supposée convexe et de classe $\\calC^1$. De plus, on sait qu'à l'itération k: \n","$w_{k+1}$:=$w_{k}$+$c_{k}$$e_{ik}$ ,\n","$c_{k}$=argmin pour(c∈$R$) $q_{k}(c)$,avec $qk(c)$:=$\\nabla_{ik}f(wk)(c−$w_{k}$i_{k}$)+12 $\\alpha_{k}$ (c −  $w_{k}$$ i_{k}$)^2.\n","On a donc une inégalité stricte:\n","f($w_{k+1}$)> f($w_k$i_{k}$)+$\\nabla $ f($w_{k}$ $i_{k}$)T(c−w_{k} $i_{k}). \n","Donc f fortement convexe.\n","\n","c_k est obtenu lorsque \\nabla_{i_k} f(\\vw_k)=0\n","\n","Donc:\n","\n","$c_{k}$=(1/2) $\\alpha_{k}$*(c−$w_{k}$  $i_{k}$)^2\n","\n","\n","*1-b)* La caractérisation nous rappelle l'utilisation de l'algorithme de gradient stochastique. On choisit un $i_k$ dans notre ensemble de jeu de données. D'autre part, en cours, on a vu que on peut traiter des données par mini-batch c'est à dire qu'on a pris un $i_k$ de telle sorte que $i_k$ soit plus grande que 1 mais reste très inférieur à n(taille du jeu de données).\n","\n","∀i=1,…,d, ∀(w,v)∈($R^{d}$)^2,|$\\nabla_{i}$ f(w)−$\\nabla_{i}$ f(v)|≤$L_{i}$ ||w−v||.\n","D'après la question 1, $f$ est strictement convexe sur d. Donc la fonction $f$ admet un unique minimiseur global $w*$ sur d.\n","Ce qui implique que pour tout i compris entre 1 et d:\n","∀(w,v)∈($R^{d}$)^2  ,  |$\\nabla_{i}$ f(w)−$\\nabla_{i}$ f(v)|≤$ L_{max}$||w−v||. ( $L_{max}$=max $L_{i}$).  \n","De plus, le gradient de $f$ est borné sur d ( d'après les propriétés de $f$) et que 1/d <= 1 pour d>=1.\n","Par conséquent, on obtient donc:\n","$L_{max}$ >=L et L >= L/d  pour tout i compris entre 1 et d\n","Par transitivité de l'inégalité, on a pour d>=1 l'inégalité suivante:\n","$L_{max}$>=L/d \n","\n","\n","\n","\n","*Votre réponse à la question 3*\n","\n","On prend une taille de pas constante pour d itérations qui nous garantit une convergence ni trop rapide ni trop lente de la fonction f et à la diminution de la fonction objective f.\n","On ne connait pas nécessairement L . Une telle information n’est pas forcément aisée à obtenir en pratique. A propos de L_max, ce choix peut conduire à un arrêt prématuré de l’algorithme en pratique. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"XQe3zmLSrjWl"},"source":["## I - B) Variantes aléatoires\n","\n","On considère maintenant des variantes de la descente par coordonnées basée sur une sélection aléatoire des coordonnées.\n","\n","Dans la suite de cette partie, on supposera que l'on a accès aux constantes de Lipschitz selon chaque coordonnée, notées $\\{L_i\\}_{i=1}^d$. On considère alors la variante de descente par coordonnée où un indice $i_k$ est tiré ***uniformément au hasard*** dans $\\{1,\\dots,d\\}$, puis le nouvel itéré est calculé comme précédemment via l'itération \n","$$\n","        \\vw_{k+1} := \\vw_k - \\frac{\\nabla_{i_k} f(\\vw_k)}{L_{i_k}} \\, \\ve_{i_k},\n","$$\n","où l'on choisit $\\frac{1}{L_{i_k}}$ comme taille de pas.\n","\n","\n","## Questions de la partie I - B)\n","\n","**Question 4** Dans cette question, on suppose que la fonction $f$ (en plus d'être convexe) possède une unique solution $\\vw^* \\in \\R^d$ et on note $f^* = f(\\vw^*)$. Pour tout $\\epsilon>0$, on peut alors montrer que l'algorithme de descente par coordonnées converge vers un itéré $\\vw_k$ tel que \n","$$\n","    \\E{\\vw_k} - f^* \\le \\epsilon \n","$$\n","en au plus\n","$$\n","    \\frac{2 d L_{\\max} \\|\\vw_0-\\vw^*\\|^2}{\\epsilon}\n","$$\n","itérations. Comparer ce résultat avec celui d'une descente de gradient sur le même problème en utilisant un pas $\\frac{1}{L}$, avec $L$ une constante de Lipschitz pour $\\nabla f$.\n","\n","\n","**Question 5** Il existe un algorithme qui combine la descente par coordonnées randomisée et l'accélération de \n","Nesterov. Partant de $\\mathbf{w}_0 \\in \\mathbb{R}^d$ et $\\mathbf{v}_0=\\mathbf{w}_0$, l'algorithme tire à chaque itération $k$ un indice $i_k$ uniformément au hasard entre $1$ et $d$, puis effectue la récursion :\n","\\begin{equation}\n","\\label{eq:nesterovcd}\n","    \\left\\{ \n","        \\begin{array}{lll}\n","            \\vu_k &:= &\\lambda_k \\vv_k + (1-\\lambda_k) \\vw_k \\\\\n","            \\vw_{k+1} &:= &\\vu_k - \\frac{1}{L_{i_k}} \\nabla_{i_k} f(\\vu_k) \\ve_{i_k} \\\\\n","            \\vv_{k+1} &:= &\\mu_k \\vv_k + (1-\\mu_k) \\vu_k - \\frac{\\gamma_k}{L_{i_k}}\\nabla_{i_k} f(\\vu) \\ve_{i_k},\n","        \\end{array}\n","    \\right.\n","\\end{equation}\n","où $\\{\\lambda_k,\\mu_k,\\gamma_k\\}$ sont des suites de réels déterminés en fonction de $d$ (voire de la constante de convexité forte si $f$ est fortement convexe).\n","\n","Cet algorithme obtient une meilleure complexité en $\\mathcal{O}(\\frac{1}{k^2})$. En observant l'itération \\eqref{eq:nesterovcd}, quel inconvénient pratique décelez-vous dans ces récursions ?\n","\n","**Question 6** Avec la stratégie \"randomisée\" décrite dans cette section, l'algorithme de descente par coordonnées rappelle l'algorithme du gradient stochastique. Il existe de fait une connection forte entre ces deux méthodes. Pour l'illustrer, on considère le problème aux moindres carrés linéaires\n","\\begin{equation}\n","\\label{eq:ermsg}\n","    \\min_{\\vv \\in \\R^d} \\frac{1}{2d} \\left\\|\\mQ \\vv -\\vy \\right\\|^2 = \\frac{1}{2d} \\sum_{i=1}^d (\\vq_i^\\T \\vv - [\\vy]_i)^2,\n","\\end{equation}\n","où $\\mQ = \\left[ \\begin{array}{c} \\vq_1^\\T \\\\ \\vdots \\\\ \\vq_d^\\T \\end{array} \\right]$ est une matrice orthogonale, c'est-à-dire inversible avec $\\mQ^\\T = \\mQ^{-1}$. Résoudre le problème \\eqref{eq:ermsg} est alors équivalent à résoudre le problème\n","\\begin{equation}\n","\\label{eq:ermcd}\n","    \\min_{\\vw \\in \\R^d} \\frac{1}{2} \\left\\|\\vw -\\vy \\right\\|^2 = \\frac{1}{2} \\sum_{i=1}^d ([\\vw]_i - [\\vy]_i)^2,\n","\\end{equation}\n","où $\\vz = \\mQ^\\T \\vy$.\n","\n","Montrer qu'une itération du gradient stochastique appliqué à \\eqref{eq:ermsg} et une itération de la descente par coordonnées randomisée appliquée à \\eqref{eq:ermcd} avec la même taille de pas et le même tirage d'indice sont équivalentes, dans le sens où si $\\vv_k = \\mQ^\\T \\vw_k$, alors $\\vv_{k+1}=\\mQ^\\T \\vw_{k+1}$.\n","\n","## *Réponses de la partie I - B)*\n","\n","*réponse question 4*\n","Avec $L$ qui est une constante dont la valeur est bien connue,il y a une garantie de convergence de l'algorithme. Par contre, l'algorithme convergera moins rapidement par rapport à $L_k$. Mais, la convergence est moins rapide ce qui engendra un coût moindre. \n","\n","*réponse question 5*\n","On peut se retrouver avec une convergence beaucoup trop rapide de la fonction f car on pourra se retrouver avec des pas de plus en plus petits lorsque k devient suffisament grand.\n","\n","\n","## Réponse question 6*\n","On sait que d'après la question 5:\n","\\begin{equation}\n","\\label{eq:nesterovcd}\n","    \\left\\{ \n","        \\begin{array}{lll}\n","            \\vu_k &= &\\lambda_k \\vv_k + (1-\\lambda_k) \\vw_k \\\\ et  \n","            \\vw_{k+1} &= &\\vu_k - \\frac{1}{L_{i_k}} \\nabla_{i_k} f(\\vu_k) \\ve_{i_k} ,\n","        \\end{array}\n","    \\right.\n","\n","En injectant l'expression de $u_k$ dans celle de $w_{k+1}$, on a alors:\n","$w_{k+1}$= $\\lambda_k$ $v_k$ + (1 - $\\lambda_k$)$w_k$ -  (1/$L_{ik}$)$\\nabla_{i_k}f(w_k)$ $e_{ik}$\n","\n","Ensuite, on obtient:\n","$w_{k+1}$= $\\lambda_k$ $v_k$ + $w_k$ - $\\lambda_k$ $v_k$ - (1/$L_{ik}$)$\\nabla_{i_k}f(w_k)$ $e_{ik}$\n","\n","Il nous reste alors:\n","\n","$w_{k+1}$=$w_k$ - (1/$L_{ik}$)$\\nabla_{i_k}f(w_k)$ $e_{ik}$\n","\n","En posant \t$\\alpha_{k}$= 1/$L_{ik}$, on peut dire que on retrouve l'itération de descente de coordonnées vu lors de la partie 1 i.e:\n","\n","$w_{k+1}$=$w_k$ - $\\alpha_{k}$$\\nabla_{i_k}f(w_k)$ $e_{ik}$\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"H6EjPmVvrjWn"},"source":["# PARTIE II - Descente par coordonnées et optimisation parcimonieuse"]},{"cell_type":"markdown","metadata":{"id":"hDJ5XZ92rjWt"},"source":["Dans cette partie, on étudie l'intérêt des méthodes de descente par coordonnées pour les problèmes de la forme\n","$$\n","    \\min_{\\vw \\in \\R^d} f(\\vw) + \\lambda \\Omega(\\vw),\n","$$\n","où $f$ sera une fonction de classe $\\calC^1$, $\\lambda>0$ et $\\Omega$ est un terme de régularisation. On supposera que $\\Omega$ possède une structure dite séparable, c'est-à-dire qu'il existe une fonction $h:[0,\\infty) \\rightarrow [0,\\infty)$ telle que\n","$$\n","    \\forall \\vw \\in \\R^d, \\quad \\Omega(\\vw) = \\sum_{i=1}^d h(\\left|[\\vw]_i \\right|).\n","$$\n","L'exemple classique d'une telle fonction est la fonction $h(t):=t$, qui conduit à une régularisation en norme $\\ell_1$ de la forme $\\Omega(\\vw):=\\|\\vw\\|_1$, avec $\\|\\vw\\|_1 := \\sum_{i=1}^d |[\\vw]_i|$. On se concentrera sur ce choix dans ce notebook pour montrer l'intérêt des méthodes de descente par coordonnées, mais on notera que les idées majeures présentées ci-dessous s'étendent à d'autres régularisations de la forme pré-citée.\n","\n","\n","## II - A) Un problème unidimensionnel\n","\n","On considère le problème\n","$$\n","    \\min_{w \\in \\mathbb{R}}\\ f_1(w), \\quad \\mbox{avec} \\quad f_1(w):= a (w-u) +  \\frac{L}{2} (w-u)^2 + \\lambda |w|,\n","$$\n","où $a,u \\in \\mathbb{R}$, $L>0$, et $\\lambda \\ge 0$.\n","\n","## Questions de la partie II - A)\n","\n","**Question 7** Montrer que ce problème est fortement convexe.\n","\n","**Question 8** On rappelle que la fonction $f_1$ est continue mais non dérivable partout. Comme vu en cours, son *sous-différentiel* est décrit par:\n","$$\n","    \\partial f_1(w) := \\left\\{\n","        \\begin{array}{ll}\n","            a + L(w-u) + \\lambda &\\mbox{si $w>0$}\\\\\n","            a + L(w-u) -\\lambda &\\mbox{si $w<0$} \\\\\n","            [a + L(w-u)-\\lambda,a + L(w-u)+\\lambda] &\\mbox{si $w=0$.}\n","        \\end{array}\n","    \\right.\n","$$\n","Ainsi, le minimum global de $\\min_{w \\in \\mathbb{R}} f_1(w)$, noté $w^*$, est caractérisé par la condition \n","$$ \n","    0 \\in \\partial f_1(w^*).\n","$$\n","\n","En utilisant ce sous-différentiel, montrer que $w^*$ est donné par\n","$$\n","    w^* = \\left\\{\n","        \\begin{array}{ll}\n","            u-\\tfrac{a}{L} - \\tfrac{\\lambda}{L} &\\mbox{si $u-\\tfrac{a}{L} > \\lambda$} \\\\\n","            u-\\tfrac{a}{L} + \\tfrac{\\lambda}{L} &\\mbox{si $u-\\tfrac{a}{L} < -\\lambda$} \\\\\n","            0 &\\mbox{si $u-\\tfrac{a}{L} \\in [-\\tfrac{\\lambda}{L},\\tfrac{\\lambda}{L}]$.}\n","        \\end{array}\n","    \\right.\n","$$\n","\n","## *Réponses de la partie II - A)*\n","\n","*Votre réponse à la question 7*\n","\n","  \\partial f_1(w) = {\n","        \\begin{array}{ll}\n","           a+L(w-u)+\\lambda\n","        \\end{array}\n","    \\right\n","  La dérivée seconde de $f_1$ s'écrit alors:\n","        \\begin{array}{ll}\n","           L>0\n","        \\end{array}\n","\n","  D'après la condition suffisante du second ordre vu en cours, la dérivée seconde est strictement positive. Donc la fonction est fortement convexe.\n","\n","\n","\n","\n","\n","*Votre réponse à la question 8*\n","Si w>0,\n","On a: \n","      \\begin{array}{ll}\n","            a + L(w^*-u) + \\lambda=0 &\\mbox{si $w>0$}\\\\\n","      \\end{array}\n","En mettant de l'autre membre de l'égalité lambda , a et en divisant par L, on obtient:\n","        \\begin{array}{ll}\n","              w^*-u=-\\lambda/L-a/L &\\mbox{si $w>0$}\\\\\n","        \\end{array}\n","Donc:\n","        \\begin{array}{ll}\n","              w^*=u-a/L-\\lambda/L &\\mbox{si $w>0$} donc &\\mbox{si $u-a/L>\\tfrac{\\lambda}{L}$}\\\\\n","        \\end{array}\n","Si w<0,\n","On a: \n","      \\begin{array}{ll}\n","            a + L(w^*-u) - \\lambda=0 &\\mbox{si $w>0$}\\\\\n","      \\end{array}\n","En mettant de l'autre membre de l'égalité lambda , a et en divisant par L, on obtient:\n","        \\begin{array}{ll}\n","              w^*-u=+\\lambda/L-a/L &\\mbox{si $w>0$}\\\\\n","        \\end{array}\n","Donc:\n","        \\begin{array}{ll}\n","              w^*=u-a/L+\\lambda/L &\\mbox{si $w>0$} donc &\\mbox{si $u-a/L>-\\tfrac{\\lambda}{L}$}\\\\\n","        \\end{array}\n","\n","\n","Si w=0,\n","On a: \n","      \\begin{array}{ll}\n","            a + L(w^*-u) + \\lambda=a + L(w^*-u) - \\lambda \n","      \\end{array}\n","Donc:\n","      \\begin{array}{ll}\n","            w^*=0\n","      \\end{array}\n","\n","\n","\n","## II-B) Cas général et descente de coordonnées par blocs\n","\n","On considère maintenant un problème de type LASSO, aussi appelé problème de poursuite de base (de l'anglais *basis pursuit*) en traitement du signal. Pour un jeu de données formé par une matrice $\\mX \\in \\R^{n \\times d}$ et un vecteur $\\vy \\in \\R^d$, ce problème s'écrit\n","\\begin{equation}\n","\\label{eq:basispursuit}\n","    \\min_{\\vw \\in \\R^d} f(\\vw)+ \\lambda \\|\\vw_1\\|, \\quad \\mbox{avec} \\quad\n","    f(\\vw):= \\frac{1}{2 n} \\|\\vy - \\mX \\vw \\|^2.\n","\\end{equation}\n","Il s'agit donc d'un problème avec régularisation $\\ell_1$. Pour le résoudre, nous allons utiliser une approche par blocs de coordonnées, dans laquelle nous utiliserons un bloc $\\setB_k \\subset \\{1,\\dots,d\\}$ de coordonnées tiré uniformément au hasard à chaque itération. Le nouveau point sera ainsi déterminé en résolvant le sous-problème\n","\\begin{equation}\n","\\label{eq:coord}\n","    \\vw_{k+1} \\in \\argmin_{\\vw} f_{\\setB_k}(\\vw):= f(\\vw_k) + \\sum_{i \\in \\setB_k} \\left\\{ \n","    \\left([\\vw]_i-[\\vw_k]_i\\right) \\nabla_i f(\\vw_k)+ \\frac{L_i}{2} \\left([\\vw]_i-[\\vw_k]_i\\right)^2 \n","    + \\lambda \\left| [\\vw_i] \\right| \\right\\},\n","\\end{equation}\n","où $L_{i_k}$ représente la constante de Lipschitz correspondant à la $i_k$-ème coordonnée, que l'on suppose connue comme en partie I-B).\n","\n","## Questions de la partie II - B)\n","\n","\n","**Question 9**  On cherche à implémenter l'algorithme ci-dessus.\n","\n","**9-a)** En utilisant le résultat de la partie II-A), justifier que le nouvel itéré de l'algorithme de descente coordonnées par blocs est donné par\n","\\begin{equation}\n","\\label{eq:bcdup}\n","    \\forall i \\in \\{1,\\dots,d\\}, \\quad \n","    [\\vw_{k+1}]_i = \\left\\{\n","    \\begin{array}{ll}\n","        [\\vw_k]_i &\\mbox{si $i \\notin \\setB_k$} \\\\\n","        [\\vw_k]_i - \\tfrac{1}{L_i} \\nabla_i f(\\vw_k) - \\tfrac{\\lambda}{L_i} &\\mbox{si $i \\in \\setB_k$ et } \n","        [\\vw_k]_i - \\tfrac{1}{L_i} \\nabla_i f(\\vw_k) > \\tfrac{\\lambda}{L_i} \\\\\n","        [\\vw_k]_i - \\tfrac{1}{L_i} \\nabla_i f(\\vw_k) + \\tfrac{\\lambda}{L_i} &\\mbox{si $i \\in \\setB_k$ et } \n","        [\\vw_k]_i - \\tfrac{1}{L_i} \\nabla_i f(\\vw_k) < - \\tfrac{\\lambda}{L_i} \\\\\n","        0 &\\mbox{sinon.}\n","    \\end{array}\n","    \\right.\n","\\end{equation}\n","\n","**9-b)** Si on choisit tous les $L_i$ égaux, à quel algorithme vu en cours correspond la variante par blocs pour laquelle $|\\setB| = n$ ?\n","\n","**Question 10** Compléter le code-ci-dessous pour implémenter un algorithme de descente par coordonnées randomisé adapté au problème \\eqref{eq:basispursuit} en utilisant la formule \\eqref{eq:bcdup}. Tester ensuite plusieurs valeurs de blocs de coordonnées en utilisant le script fourni, et commenter vos résultats.\n","\n","\n","## *Réponses aux questions de la partie II - B)*\n","**Réponse 9.A**\n","\n","En se basant sur les réponses à la partie 2.A on a :\n","\n","$$\n","    w^* = \\left\\{\n","        \\begin{array}{ll}\n","          (1)  u-\\tfrac{a}{L} - \\tfrac{\\lambda}{L} &\\mbox{si $u-\\tfrac{a}{L} > \\lambda$} \\\\   \n","           (2) u-\\tfrac{a}{L} + \\tfrac{\\lambda}{L} &\\mbox{si $u-\\tfrac{a}{L} < -\\lambda$} \\\\  \n","         (3)   0 &\\mbox{si $u-\\tfrac{a}{L} \\in [-\\tfrac{\\lambda}{L},\\tfrac{\\lambda}{L}]$.} \n","        \\end{array}\n","    \\right.\n","$$\n","\n","Cela se traduit en étudiant 4 conditions différentes afin de parvenir au résultat final:\n","\n","Si $i \\notin \\setB_k$, alors on se retrouve dans le cas ou le problème de régularisation $l_{1}$ ne contient pas de bloc $B_{k}$. Ainsi, le terme à l'intérieur de la somme des $B{k}$ est nulle.\n","Donc $w_{k+1}${i}= 0 pour $i \\notin \\setB_k$\n","\n","Si $i \\in \\setB_k$ et que $w_{k}$_{i} - (1/$L_{i}$) $\\nabla_{i} f($w_{k}$) > (\\lambda / $L_{i}$) alors on se retrouve dans le cas (2) ci-dessus car c'est compatible avec les propriétés des deux problèmes vus dans les deux parties.\n","Donc:\n","\n","$w_{k+1}$=[$w_k$]_i - (1/$L_{i}$) $\\nabla_{i} f($w_{k}$) - (\\lambda/$L_{i}$)\n","\n","Si $i \\in \\setB_k$ et que $w_{k}$_{i} - (1/$L_{i}$ $\\nabla_{i} f($w_{k}$) < $\\lambda$/ $L_{i}$ alors on se retrouve dans le cas (1) ci-dessus car c'est compatible avec les propriétés des deux problèmes vus dans les deux parties.\n","Donc:\n","\n","$w_{k+1}$=[$w_k$]_i - (1/$L_{i}$) $\\nabla_{i} f($w_{k}$) + (\\lambda/ $L_{i}$)\n","\n","Sinon, si i ne vérifie aucune des trois conditions ci-dessus, alors on se retrouve dans le cas (3) ci-dessus car c'est compatible avec les propriétés des deux problèmes vus dans les deux parties.\n","\n","Donc:\n","\n","$w_{k+1}$=0\n","\n","\n","\n","\n","**Réponse 9.B** \n","Lorsque $|\\setB| = n$, on retrouve l'algorithme de gradient proximal vu en cours. Ainsi, l’approche proximale procède selon un schéma très fréquent en optimisation : un problème donné est remplacé par une suite de sous-problèmes présumés plus faciles à résoudre. Dans le cas des méthodes proximales, on exploite la dérivabilité de f pour obtenir un problème plus simple.\n","\n","*Vos commentaires concernant la question 10*"]},{"cell_type":"code","metadata":{"id":"HVsp8-oGoFn9"},"source":["# Ajout des librairies servant à répondre à la question\n","\n","%matplotlib inline\n","\n","from math import sqrt # Racine carrée\n","import numpy as np # NumPy (calcul scientifique)\n","from scipy.linalg import norm # Norme euclidienne\n","import matplotlib.pyplot as plt # Affichage\n","from numba import njit, jit, jitclass  # Compilation en temps réel pour accélérer l'exécution"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kSgPvn5VrjWw"},"source":["# Implémentation de l'algorithme de descente par coordonnées randomisé (RCD)\n","# À compléter pour répondre à la question 10\n","def rcd_lasso(w0,X,y,lbda,nblocs,nits=500): \n","    \"\"\"\n","        Code de la descente par coordonnées pour les problèmes de type LASSO de la forme\n","        \n","        Entrées :\n","            w0: Point initial\n","            X : Matrice du problème concerné\n","            y : Vecteur du problème concerné\n","            lbda : Coefficient de régularisation\n","            nits: Nombre maximum d'itérations à effectuer, utilisé comme critère d'arrêt\n","            \n","        Sorties :\n","            w_output : Dernier itéré calculé par l'algorithme\n","            objvals : Historique des valeurs de fonction (tableau Numpy de longueur au plus nits)\n","            nnzvals : Historique de parcimonie des itérés (tableau Numpy de longueur au plus nits)\n","    \"\"\"\n","    \n","    ############\n","    # Initialisation des historiques\n","    # Historique des valeurs de fonctions\n","    objvals = []\n","    #Historique des normes des gradients\n","    nnzvals = []\n","    \n","    # Valeur initiale de l'itéré (le .copy() permet de ne pas modifier le point de départ) \n","    w = w0.copy()\n","\n","    # Initialisation de l'indice d'itération\n","    k=0    \n","    \n","    # Dimensions\n","    n,d = X.shape\n","    #affichage des dimensions de X(200*200)\n","    # Constantes de Lipschitz\n","    ell = norm(np.matmul(X.T,X),axis=0)\n","    # Calcul de l'objectif en le point initial+Ajout à l'historique\n","    obj = norm(X.dot(w) - y) ** 2 / (2. * n) + lbda * norm(w,1)\n","    objvals.append(obj)\n","    \n","    # Calcul du nombre de coefficients non nuls dans l'itéré\n","    nnzvals.append(np.count_nonzero(w))\n","    \n","    #### PARTIE A COMPLETER\n","    # Calcul du gradient de la partie lisse en le point initial(g est un float)\n","    g =(1/n)*norm(y-X.dot(w))\n","    print(y.shape)\n","    #### FIN PARTIE A COMPLETER\n","    ng = norm(g)\n","    #ajout de la norme du gradient dans la liste nnzvals\n","    nnzvals.append(ng)\n","\n","\n","    #########################\n","    # Début boucle principale\n","    while (k < nits):\n","        \n","        ### DEBUT PARTIE A COMPLETER\n","        # Tirage aléatoire de la ou des coordonnées avec nblocs blocs de coordonnée en sortie(1 bloc de coordonnées est choisi en paramétrant replace à la valeur False)\n","        ik = np.random.choice(n,nblocs,replace=False)\n","        # Calcul du gradient de la partie lisse en le nouveau point\n","        g =(1/n)*norm(y-X.dot(w))     \n","        # Calcul du nouvel itéré par composantes (modifier le vecteur w existant) \n","        for j in range(d):\n","            step=1/ell[j]\n","            valeuri = w[j]-step*g\n","            #threshold: frontière (=lambda/ell[j])\n","            threshold = step*lbda\n","            #pour les conditions à implémenter en python on se base sur l'énoncé de la question 9-a°)\n","            #si j n'est pas dans le bloc B_k( condition 1)\n","            if j not in ik:\n","              w[:]=w\n","            #si j est dans le bloc B_k et que l'itération suivante est strictement à -lambda/L_i( )\n","            if valeuri < -threshold and j in ik:\n","                w[j] = valeuri+threshold\n","            #si j est dans le bloc B_k et que l'itération suivante est strictement supérieure à lambda/L_i\n","            elif valeuri > threshold and j in ik:\n","                w[j] = valeuri-threshold\n","            #sinon \n","            else:\n","                w[j] = 0\n","        ### FIN PARTIE A COMPLETER\n","        ng = norm(g)\n","        nnzvals.append(ng)\n","        # Calcul de l'objectif en le nouveau point ()\n","        obj = norm(X.dot(w) - y) ** 2 / (2. * n) + lbda * norm(w,1)\n","        objvals.append(obj)\n","        \n","        \n","        # Calcul du nombre de coefficients non nuls en le nouveau point\n","        nnzvals.append(np.count_nonzero(w))\n","        \n","        k += 1  \n","    # Fin boucle principale   \n","    #######################\n","    \n","    w_output = w.copy()\n","          \n","    return w_output, np.array(objvals), np.array(nnzvals)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NlRx7gnirjWx","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1611047713522,"user_tz":-60,"elapsed":19561,"user":{"displayName":"JULIEN VU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-WovJPI2yPidc_awdc77pL4cna4IDF3nnYW07Iw=s64","userId":"06342654057600854555"}},"outputId":"92ababa1-8a84-4122-8f2d-7e0d7335b5eb"},"source":["# Script de validation de l'implémentation de la question 10\n","\n","################# Imports préliminaires\n","%matplotlib inline\n","\n","import numpy as np # NumPy (calcul scientifique)\n","from scipy.linalg import norm # Norme euclidienne\n","import matplotlib.pyplot as plt # Affichage\n","\n","############### Etape 1 - Génération des données avec une vérité terrain parcimonieuse\n","#\n","# Les coefficients de X suivent une loi normale N(0,1/n)\n","# Le vecteur y est obtenu via y = X*w+eps, où\n","#    w est un vecteur creux (10% de coefficients non nuls)\n","from numpy.random import multivariate_normal, randn\n","\n","d = 200\n","n = 200\n","s = round(0.9*min(d,n))\n","X = multivariate_normal(np.zeros(d), (1/n)*np.identity(d), size=n)\n","idx = np.arange(d)\n","\n","# Coefficients du vrai modèle (\"vérité terrain/ground truth\")\n","wtrue = (-1)**idx * np.exp(-idx / 10.)\n","ip = np.random.permutation(d)\n","wtrue[ip[0:s]]=0\n","\n","Xw = X.dot(wtrue)\n","std = (0.01/n)*(norm(Xw)**2)\n","noise = std * randn(n)\n","y = Xw + noise\n","print(X.shape)\n","print(y.shape)\n","w0 = np.ones(d)\n","lbda = 1/ (n**0.5)\n","\n","################# Etape 2 - Tester plusieurs valeurs de tailles de bloc\n","\n","\n","nb=1\n","nits=2000\n","w1,obj1,nnz1 = rcd_lasso(w0,X,y,lbda,nb,nits)\n","print('Nombre de bloc(s) :',nb)\n","print('Valeur objectif :',obj1[-1])\n","print('Pourcentage coefficients non nuls :',(d-nnz1[-1])*100/d)\n","nb=int(d/100)\n","w2,obj2,nnz2 = rcd_lasso(w0,X,y,lbda,nb,nits)\n","print('Nombre de bloc(s) :',nb)\n","print('Valeur objectif :',obj2[-1])\n","print('Pourcentage coefficients non nuls :',(d-nnz2[-1])*100/d)\n","nb=int(d/20)\n","w3,obj3,nnz3 = rcd_lasso(w0,X,y,lbda,nb,nits)\n","print('Nombre de bloc(s) :',nb)\n","print('Valeur objectif :',obj3[-1])\n","print('Pourcentage coefficients non nuls :',(d-nnz3[-1])*100/d)\n","nb=d\n","w4,obj4,nnz4 = rcd_lasso(w0,X,y,lbda,nb,nits)\n","print('Nombre de bloc(s) :',nb)\n","print('Valeur objectif :',obj4[-1])\n","print('Pourcentage coefficients non nuls :',(d-nnz4[-1])*100/d)\n","\n","################# Etape 3 - Affichage des résultats\n","\n","\n","\n","# En termes de fonction objectif (échelle logarithmique sur l'axe des ordonnées)\n","plt.figure(figsize=(7, 5))\n","plt.semilogy(obj1, label=\"nb=1\", color='indianred',lw=2)\n","plt.semilogy(obj2, label=\"nb=d/100\", color='brown', lw=2)\n","plt.semilogy(obj3, label=\"nb=d/20\", color='red', lw=2)\n","plt.semilogy(obj3, label=\"nb=d\", color='darkred', lw=2)\n","plt.title(\"Convergence des méthodes\", fontsize=16)\n","plt.xlabel(\"#Iterations\", fontsize=14)\n","plt.ylabel(\"Objectif (log)\", fontsize=14)\n","plt.legend()\n","\n","# Évolution du nombre de coordonnées nulles\n","plt.figure()\n","itnum = np.arange(nits+1)\n","print(itnum.shape)\n","print(nnz4.shape)\n","plt.scatter(itnum,nnz1,color='m',marker='o',label='nb=1')\n","plt.scatter(itnum,nnz2,color='indigo',marker='d',label='nb=d/100')\n","plt.scatter(itnum,nnz3,color='b',marker='*',label='nb=d/20')\n","plt.scatter(itnum,nnz4,color='dodgerblue',marker='x',label='nb=d')\n","plt.title(\"Parcimonie des itérés\", fontsize=16)\n","plt.xlabel(\"#Iterations\", fontsize=14)\n","plt.ylabel(\"Coefficients non nuls\", fontsize=14)\n","plt.legend()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(200, 200)\n","(200,)\n","(200,)\n","Nombre de bloc(s) : 1\n","Valeur objectif : 0.002602362763982587\n","Pourcentage coefficients non nuls : 100.0\n","(200,)\n","Nombre de bloc(s) : 2\n","Valeur objectif : 0.002602362763982587\n","Pourcentage coefficients non nuls : 100.0\n","(200,)\n","Nombre de bloc(s) : 10\n","Valeur objectif : 0.002602362763982587\n","Pourcentage coefficients non nuls : 100.0\n","(200,)\n","Nombre de bloc(s) : 200\n","Valeur objectif : 0.002602362763982587\n","Pourcentage coefficients non nuls : 100.0\n","(2001,)\n","(4002,)\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-2b5bfcd61f62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitnum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnz4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnnz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nb=1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnnz2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'indigo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nb=d/100'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnnz3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nb=d/20'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2814\u001b[0m         \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m         plotnonfinite=plotnonfinite, **({\"data\": data} if data is not\n\u001b[0;32m-> 2816\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2817\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2818\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4389\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4391\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: x and y must be the same size"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 504x360 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"hqJR1-pfrjWx"},"source":["CC Outils d'optimisation pour les sciences des données et de la décision\n"," Version 1.0 - *C. W. Royer, janvier 2021.*"]}]}